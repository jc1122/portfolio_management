# Asset Selection Script: `select_assets.py`

## Overview

This script is the second step in the portfolio management toolkit's data pipeline, following data preparation. Its purpose is to act as a powerful, data-driven filter, refining the master list of all matched instruments into a smaller, high-quality universe of assets that are suitable for financial analysis.

This selection is based on **technical and data-quality criteria only** (e.g., data completeness, market, currency). It does not perform any financial analysis like assessing risk, return, or correlation.

## Inputs (Prerequisites)

Before running the script, you must have the following:

1. **Python Environment**: Python 3.10+ with the `pandas` library installed.
1. **Match Report (Required)**: The primary input is the `tradeable_matches.csv` file generated by the `prepare_tradeable_data.py` script. This file contains the list of all available instruments and their data quality flags.
1. **Allow/Block Lists (Optional)**: You can provide optional text files to manually force-include or exclude specific assets.
   - **Format**: Plain text files with one symbol or ISIN per line.

## Script Products

The script produces one primary output and one alternative console output.

1. **Selected Assets CSV (Primary Product)**

   - **Location**: The path specified by the `--output` argument (e.g., `/tmp/selected_assets.csv`).
   - **Description**: This is the main product. It is a CSV file containing the filtered list of assets that passed all the specified criteria. Its structure is identical to the input `tradeable_matches.csv`, but it contains only the subset of selected rows. This file serves as the direct input for the next workflow step, `scripts/classify_assets.py`.

1. **Console Output (Alternative)**

   - If you run the script with the `--dry-run` flag, it will print a summary of what would be selected without creating a file.
   - If you run the script without specifying an `--output` path, it will print the entire resulting DataFrame to the console.

## Features (Filtering Criteria)

The script's main feature is its rich set of filtering criteria, which are controlled via command-line arguments.

### Data Quality Filters

- `--data-status`: Filters assets by their overall data quality grade. The definitions for `ok`, `warning`, and `error` are [documented here](./data_preparation.md#data-status).
- `--severity`: Filters by the severity of any zero-volume warnings.

### History and Data Coverage Filters

- `--min-history-days`: Enforces a minimum number of calendar days of price history.
- `--min-price-rows`: Enforces a minimum number of actual data points (trading days).
- `--max-gap-days`: Sets a maximum tolerance for gaps (in days) between consecutive data points.

### Categorical Filters

- `--markets`: Restricts the selection to a specific list of markets (e.g., `"LSE,NYSE"`).
- `--regions`: Restricts the selection to a specific list of geographic regions.
- `--currencies`: Restricts the selection to a specific list of currencies.

> **Tip:** The available values for `markets`, `regions`, and `currencies` depend on the content of your `tradeable_matches.csv` file. To see which values you can filter by, you should inspect the unique values present in these columns in that file.

### Manual Override Filters

- `--allowlist`: A file path to a list of symbols/ISINs to **force-include**, regardless of other filters.
- `--blocklist`: A file path to a list of symbols/ISINs to **always exclude**.

## Usage Example

Here is a typical command to select assets from the US and UK with at least two years of high-quality data:

```bash
python scripts/select_assets.py \
    --match-report data/metadata/tradeable_matches.csv \
    --output /tmp/selected_assets.csv \
    --min-history-days 730 \
    --markets "LSE,NYSE,NSQ" \
    --data-status "ok"
```

## Command-Line Arguments

- `--match-report`: **(Required)** Path to the `tradeable_matches.csv` file.
- `--output`: Path to save the output CSV file. If omitted, prints to the console.
- `--data-status`: Comma-separated list of allowed data quality statuses. Default: `ok`.
- `--min-history-days`: Minimum number of calendar days of price history. Default: `252`.
- `--min-price-rows`: Minimum number of data rows (trading days). Default: `252`.
- `--max-gap-days`: Maximum allowed gap in days between consecutive prices. Default: `10`.
- `--severity`: Comma-separated list of zero-volume severity levels to include.
- `--markets`: Comma-separated list of market codes to include.
- `--regions`: Comma-separated list of regions to include.
- `--currencies`: Comma-separated list of currencies to include.
- `--allowlist`: Path to a file with symbols/ISINs to force-include.
- `--blocklist`: Path to a file with symbols/ISINs to exclude.
- `--verbose`: Enable detailed logging output.
- `--dry-run`: Show a summary of what would be selected without writing any files.
- `--chunk-size`: Enable streaming mode with the specified chunk size (e.g., `5000`). When not specified, loads the entire file into memory (default behavior).

## Memory Management: Streaming Mode

For large match reports (tens of thousands of rows or more), the script offers a **streaming mode** that processes the CSV file in configurable chunks rather than loading it all into memory at once.

### When to Use Streaming Mode

- **Large Files**: Match reports with tens of thousands of rows
- **Memory-Constrained Environments**: When running on systems with limited RAM
- **Production Pipelines**: When consistent memory usage is critical

### How to Enable Streaming Mode

Use the `--chunk-size` parameter to specify how many rows to process at a time:

```bash
python scripts/select_assets.py \
    --match-report data/metadata/tradeable_matches.csv \
    --output /tmp/selected_assets.csv \
    --min-history-days 730 \
    --markets "LSE,NYSE,NSQ" \
    --data-status "ok" \
    --chunk-size 5000
```

### Streaming Mode Guarantees

- **Identical Results**: Streaming mode produces exactly the same output as eager loading
- **Bounded Memory**: Memory usage is limited to processing `chunk-size` rows at a time
- **Allowlist Validation**: When using `--allowlist`, the script validates that all required symbols are found across all chunks and raises an error if any are missing
- **Blocklist Support**: The blocklist is applied to each chunk independently

### Performance Considerations

- **Chunk Size**: Typical values range from 1,000 to 10,000 rows
  - Smaller chunks: Lower memory usage, more overhead
  - Larger chunks: Higher memory usage, less overhead
- **Default Behavior**: When `--chunk-size` is not specified, the script uses eager loading (loads entire file)
- **Recommendation**: Start with `--chunk-size 5000` for files over 50,000 rows
